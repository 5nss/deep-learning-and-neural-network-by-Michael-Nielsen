This repository documents my journey learning the fundamentals of Deep Learning by working through **[Michael Nielsen's "Neural Networks and Deep Learning"](http://neuralnetworksanddeeplearning.com/)**.

## ğŸ“‚ Repository Structure
* **Chapter 1:** Basics of Perceptrons, Sigmoid Neurons, and Standard Gradient Descent.
    * *Exercises:* Hand-written proofs and code modifications.
* **Chapter 2:** The Backpropagation Algorithm (BP1 - BP4 equations).
    * *Implementation:* Matrix-based backprop from scratch.

## ğŸ› ï¸ Tech Stack
* **Python**
* **NumPy** (for linear algebra operations)
* **Matplotlib** (for visualizing results)

## ğŸ“ Key Learnings
* **Gradient Descent:** How the network "rolls down the hill" to minimize cost.
* **Backpropagation:** Understanding how error is attributed to weights using the Chain Rule.
* **Activation Functions:** Why we need non-linearity (Sigmoid).
